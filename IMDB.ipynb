{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31d89499",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f733d6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('IMDB Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3993d1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(df['review'],df['sentiment'],test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "befb4357",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_train_encoded = le.fit_transform(y_train)\n",
    "y_test_encoded  = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49f4592c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(num_words=5000)  # Adjust num_words based on dataset size\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "x_train_sequences = tokenizer.texts_to_sequences(x_train)\n",
    "x_test_sequences = tokenizer.texts_to_sequences(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e62568c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "max_len = 100  # Adjust max_len based on average review length\n",
    "x_train_padded = pad_sequences(x_train_sequences, maxlen=max_len, padding=\"post\")\n",
    "x_test_padded = pad_sequences(x_test_sequences, maxlen=max_len, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06982c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(5000, 128, input_length=max_len))  # Embedding layer\n",
    "model.add(LSTM(64))  # LSTM layer\n",
    "model.add(Dense(1, activation=\"sigmoid\"))  # Output layer with sigmoid activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3dd75bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1250/1250 [==============================] - 129s 99ms/step - loss: 0.3854 - accuracy: 0.8252\n",
      "Epoch 2/5\n",
      "1250/1250 [==============================] - 123s 99ms/step - loss: 0.2706 - accuracy: 0.8887\n",
      "Epoch 3/5\n",
      "1250/1250 [==============================] - 124s 100ms/step - loss: 0.2253 - accuracy: 0.9078\n",
      "Epoch 4/5\n",
      "1250/1250 [==============================] - 125s 100ms/step - loss: 0.1860 - accuracy: 0.9258\n",
      "Epoch 5/5\n",
      "1250/1250 [==============================] - 125s 100ms/step - loss: 0.1540 - accuracy: 0.9416\n",
      "313/313 [==============================] - 14s 40ms/step - loss: 0.3636 - accuracy: 0.8634\n",
      "Test Accuracy: 0.8633999824523926\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train_padded, y_train_encoded, epochs=5, batch_size=32) # validation_data=(X_test_padded, y_test_encoded)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(x_test_padded, y_test_encoded)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de3aa150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 71ms/step\n",
      "Predicted sentiment: Positive\n"
     ]
    }
   ],
   "source": [
    "new_review = \"The plot was good and the acting was awesome.\"  # Replace with your review\n",
    "new_padded = pad_sequences(tokenizer.texts_to_sequences([new_review]), maxlen=100, padding=\"post\")\n",
    "sentiment = \"Positive\" if model.predict(new_padded) > 0.5 else \"Negative\"\n",
    "print(\"Predicted sentiment:\", sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4074c1f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
